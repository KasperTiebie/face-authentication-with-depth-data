{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2.pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from fpdf import FPDF\n",
    "import unicodedata\n",
    "\n",
    "inputdirectory = \"framesets\"\n",
    "outputdirectory = \"faces\"\n",
    "\n",
    "\n",
    "def unicode_normalize(s):\n",
    "    return unicodedata.normalize('NFKD', s).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Classroom_10_Erik.bag\n",
      "Analyzing: Classroom_11_Erwin.bag\n",
      "Analyzing: Classroom_12_Tim.bag\n",
      "Analyzing: Classroom_13_Tom.bag\n",
      "Analyzing: Classroom_14_Johnny.bag\n",
      "Analyzing: Classroom_15_Dennis.bag\n",
      "Warning! Multiple Faces Detected!\n",
      "Analyzing: Classroom_16_Dennis.bag\n",
      "Analyzing: Classroom_17_Lisanne.bag\n",
      "Analyzing: Classroom_18_Bryan.bag\n",
      "Analyzing: Classroom_19_Eline.bag\n",
      "Analyzing: Classroom_1_Sander.bag\n",
      "Analyzing: Classroom_20_Rick.bag\n",
      "Analyzing: Classroom_21_Arthur.bag\n",
      "Analyzing: Classroom_2_Oscar.bag\n",
      "Analyzing: Classroom_3_Kristo.bag\n",
      "Analyzing: Classroom_4_Arthur.bag\n",
      "Analyzing: Classroom_5_Dylan.bag\n",
      "Warning! Multiple Faces Detected!\n",
      "Analyzing: Classroom_6_Jacintha.bag\n",
      "Analyzing: Classroom_7_Julia.bag\n",
      "Analyzing: Classroom_8_Julia.bag\n",
      "Analyzing: Classroom_9_Roald.bag\n",
      "Analyzing: Test_1_Kasper.bag\n",
      "Analyzing: Test_2_Kasper.bag\n",
      "Warning! No Faces Detected!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = FPDF()\n",
    "for filename in os.listdir(inputdirectory):\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    # Configure depth and color streams\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    colorizer = rs.colorizer()\n",
    "\n",
    "    rs.config.enable_device_from_file(config, os.path.join(inputdirectory, filename))\n",
    "    config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
    "    config.enable_stream(rs.stream.color, rs.format.bgr8, 30)\n",
    "\n",
    "    # Start the pipeline\n",
    "    profile = pipeline.start(config)\n",
    "\n",
    "    # Extract depth scale\n",
    "    depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "    # Initialize the Haar-cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier();\n",
    "    face_cascade.load(\"ext/haarcascade_frontalface_default.xml\");\n",
    "\n",
    "    # Wait for a coherent pair of frames: depth and color\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    depth_color_frame = rs.colorizer().colorize(depth_frame)\n",
    "    color_frame = frames.get_color_frame()\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    depth_colormap = np.asanyarray(depth_color_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    depth_colormap_dim = depth_colormap.shape\n",
    "    color_colormap_dim = color_image.shape\n",
    "\n",
    "    # Apply Haar-cascade classifier\n",
    "    faces = face_cascade.detectMultiScale(gray_image)\n",
    "\n",
    "    # Extract a copy of the original images to draw onto\n",
    "    color_image_display = color_image.copy()\n",
    "    depth_colormap_display = depth_colormap.copy()\n",
    "\n",
    "    if len(faces) > 1:\n",
    "        print(\"Warning! Multiple Faces Detected!\")\n",
    "    elif len(faces) < 1:\n",
    "        print(\"Warning! No Faces Detected!\")\n",
    "\n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "        extracted_face_color = color_image[y-30:y+h+30,x-30:x+w+30]\n",
    "        extracted_face_color = np.rot90(extracted_face_color)\n",
    "        cv2.imwrite(os.path.join(outputdirectory, filename + \"_\" + str(i) + \".png\"), extracted_face_color)\n",
    "        #outputHeight = 297-25.4*2\n",
    "        outputWidth = 210-31.7*2 # = h+30\n",
    "        outputHeight = ((297-25.4*2)/(h+60))*(210-31.7*2)\n",
    "        \n",
    "        pdf.add_page()\n",
    "        pdf.image(os.path.join(outputdirectory, filename + \"_\" + str(i) + \".png\"),0+31.7,0+25.4,outputWidth,outputHeight)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    pipeline.stop()\n",
    "\n",
    "# Save PDF\n",
    "pdf.output(\"faces/extracted_faces.pdf\", \"F\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('onderzoek')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06f1ba10863b5962b8e4e5709ffe051ecd7fdc78a47556591065a2148081dea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
